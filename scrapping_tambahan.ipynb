{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <h3><b>Selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUKA CHROME\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument('--no-sandbox')\n",
    "chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "chrome_options.add_argument('--disable-gpu')\n",
    "\n",
    "driver = webdriver.Chrome(options=chrome_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Fungsi untuk menghapus pengulangan kata\n",
    "def remove_duplicate_words(text):\n",
    "    words = text.split()\n",
    "    unique_words = []\n",
    "    for word in words:\n",
    "        if word not in unique_words:\n",
    "            unique_words.append(word)\n",
    "    return ' '.join(unique_words)\n",
    "\n",
    "def add_spasi(text):\n",
    "    hasil = re.sub(r'(?<=[a-z])([A-Z])', r' \\1', text)\n",
    "    return hasil "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "www.business2community.com checking if the site connection is secure needs to review security of your before proceeding. ray id: 8122031dbc699fc8 performance & by cloudflare\n"
     ]
    }
   ],
   "source": [
    "driver.get(\"https://www.business2community.com/gambling/singapore-online-gambling\")\n",
    "time.sleep(5)\n",
    "\n",
    "# Printing the whole body text\n",
    "teks = driver.find_element(By.XPATH, \"/html/body\").text\n",
    "\n",
    "# clean dikit\n",
    "kalimat = add_spasi(teks)\n",
    "kalimat = remove_duplicate_words(kalimat.lower())\n",
    "\n",
    "print(kalimat)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><b>Prepro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Prepo/kbba.txt', 'r', encoding='utf-8') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "data = [line.strip().split('\\t') for line in lines]\n",
    "\n",
    "data_singkatan = pd.DataFrame(data, columns=['Contraction', 'Meaning'])\n",
    "df_en = pd.read_csv(\"Prepo/contractions.csv\")\n",
    "\n",
    "# Menggabungkan DataFrames secara vertikal (menambahkan baris)\n",
    "df_singkatan = pd.concat([data_singkatan, df_en], ignore_index=True)\n",
    "\n",
    "# Ubah DataFrame menjadi kamus\n",
    "kontraksi_dict = dict(zip(df_singkatan['Contraction'], data_singkatan['Meaning']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Fungsi untuk menghapus kata-kata dengan satu huruf\n",
    "def remove_tag(text):\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if not word.startswith('#')]  # Menghapus kata-kata yang dimulai dengan '#'\n",
    "    filtered_words = [word for word in filtered_words if not word.startswith('http')]  # Menghapus kata-kata yang dimulai dengan '#'\n",
    "    filtered_words = [word for word in filtered_words if not word.startswith('https')]  # Menghapus kata-kata yang dimulai dengan '#'\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "# Fungsi untuk menghapus tanda baca\n",
    "def remove_punctuation(text):\n",
    "    hasil = re.sub(r'[^\\w\\s]', '', text)\n",
    "    return hasil\n",
    "\n",
    "# Fungsi untuk mengatasi kontraksi dalam bahasa Indonesia\n",
    "def expand_contractions_id(text):\n",
    "    kontraksi_dict\n",
    "    \n",
    "    words = text.split()\n",
    "    expanded_text = [kontraksi_dict[word] if word in kontraksi_dict else word for word in words]\n",
    "    return ' '.join(expanded_text)\n",
    "\n",
    "def ubah_angka(text):\n",
    "    # Menggunakan regular expression untuk mengganti karakter alay\n",
    "    teks_benar = re.sub(r'3', 'e', text)\n",
    "    teks_benar = re.sub(r'4', 'a', teks_benar)\n",
    "    teks_benar = re.sub(r'1', 'i', teks_benar)\n",
    "    teks_benar = re.sub(r'0', 'o', teks_benar)\n",
    "\n",
    "    # Menggunakan regular expression untuk memisahkan angka yang terikat dengan kata \"mekinya\"\n",
    "    # angka = re.search(r'(\\d+)$', teks_benar).group(1)\n",
    "    # teks_benar = re.sub(r'\\d+$', '', teks_benar)\n",
    "\n",
    "    # # Menggabungkan kembali teks dengan angka\n",
    "    # hasil_akhir = teks_benar + angka\n",
    "    return teks_benar\n",
    "\n",
    "def remove_number(text) :\n",
    "    hasil = re.sub(r'\\d', '', text)\n",
    "    return hasil\n",
    "\n",
    "# Fungsi untuk menghapus tautan dari teks\n",
    "def remove_links(text):\n",
    "    # Menggunakan ekspresi reguler untuk mencari dan menghapus tautan\n",
    "    return re.sub(r'http\\S+|www\\S+|https\\S+', '', text)\n",
    "\n",
    "# Fungsi untuk menghapus kata-kata dengan satu huruf\n",
    "def remove_single_letter_words(text):\n",
    "    text = re.sub(r'\\b\\w\\b', '', text)\n",
    "    \n",
    "    hapus = ['rj','lc','en','ar','mc','vt','rob','ny','dc','az','va']\n",
    "    words = text.split()\n",
    "\n",
    "    # Memfilter kata-kata yang tidak ada dalam array yang akan dihapus\n",
    "    kata_kata_tanpa_kata_yang_dihapus = [kata for kata in words if kata not in hapus]\n",
    "\n",
    "    # Menggabungkan kata-kata yang tersisa menjadi kalimat baru\n",
    "    kalimat_tanpa_kata_yang_dihapus = ' '.join(kata_kata_tanpa_kata_yang_dihapus)\n",
    "    return kalimat_tanpa_kata_yang_dihapus\n",
    "\n",
    "# Preprocessing kolom 'text'\n",
    "kalimat = remove_tag(kalimat)\n",
    "kalimat = remove_punctuation(kalimat)\n",
    "kalimat = expand_contractions_id(kalimat)\n",
    "kalimat = ubah_angka(kalimat)\n",
    "kalimat = remove_number(kalimat)\n",
    "kalimat = remove_links(kalimat)\n",
    "kalimat = remove_single_letter_words(kalimat)\n",
    "\n",
    "# Menampilkan DataFrame setelah preprocessing\n",
    "# df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deep_translator import GoogleTranslator\n",
    "\n",
    "def translate(text):\n",
    "    # to_translate = 'I want to translate this text'\n",
    "    translated = GoogleTranslator(source='auto', target='en').translate(text)\n",
    "    return translated\n",
    "\n",
    "# Preprocessing kolom 'text'\n",
    "kalimat = translate(kalimat[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "from Sastrawi.StopWordRemover.StopWordRemover import StopWordRemover\n",
    "\n",
    "# Download stopwords (jika belum diunduh)\n",
    "nltk.download('stopwords')\n",
    "# Ambil daftar stopwords dalam bahasa Inggris\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Inisialisasi stopword remover dari Sastrawi\n",
    "factory = StopWordRemoverFactory()\n",
    "stopword_remover = factory.create_stop_word_remover()\n",
    "\n",
    "stop_words = list(stop_words)\n",
    "tambahan = ['entertainment','recreation','joined','june','following','iek','followers','create','agree','terms','service','sep','media','privacy','policy','including','use','relevant','google','apple','bookmarks','signing','account','follow','instagram','happening','people','know','post','conversation','twitter','dont','whats','first','sign','news','maps','share','feedback','indonesia','ay','setting','settings','eop','iim','iomin','ioop','op','welcome','paling','skip','content','menu','belum','ai','month','year','day','lanjut','access','ads','ok','must','ee','ao','login','oa','data','connection','ia','cookies','us','log','kami','dlvr','id','co','p','ly','youtu','bal','nder','nak','http','rm','whq','com','st','pth','html','bz','ss','cc','tt','oi','ie','io','ii','oe','ik','cookie','eo','ak','ek','ioo','vr','ea','oo','ei','usc']\n",
    "stop_words.extend(tambahan)\n",
    "\n",
    "# Menghapus stopwords dari kolom 'text'\n",
    "kalimat = ' '.join([word for word in kalimat.split() if word.lower() not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dadang jsn front page site home study materials elementary middle school classes, complete semester natural sciences, write comment, education friends happy learning opportunity time, natural sciences, SDMI accessed directly online used e-learning school home field study iv odd full chapter human skeleton, maintenance function, human function, influence body posture growth'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kalimat"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <h3><b>CFSCRAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Fungsi untuk menghapus pengulangan kata\n",
    "def remove_duplicate_words(text):\n",
    "    words = text.split()\n",
    "    unique_words = []\n",
    "    for word in words:\n",
    "        if word not in unique_words:\n",
    "            unique_words.append(word)\n",
    "    return ' '.join(unique_words)\n",
    "\n",
    "def add_spasi(text):\n",
    "    hasil = re.sub(r'(?<=[a-z])([A-Z])', r' \\1', text)\n",
    "    return hasil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamblingsites.org please enable js and disable any ad blocker\n"
     ]
    }
   ],
   "source": [
    "import cfscrape \n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "scraper = cfscrape.create_scraper() \n",
    "scraped_data = scraper.get(\"https://www.gamblingsites.org/\") \n",
    "\n",
    "soup = BeautifulSoup(scraped_data.text, 'html.parser')\n",
    "text = soup.get_text()\n",
    "\n",
    "# print(text)\n",
    "# clean dikit\n",
    "kalimat = add_spasi(text)\n",
    "kalimat = remove_duplicate_words(kalimat.lower())\n",
    "\n",
    "print(kalimat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 (tags/v3.10.9:1dd9be6, Dec  6 2022, 20:01:21) [MSC v.1934 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
